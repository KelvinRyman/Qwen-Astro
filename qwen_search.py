import requests
from bs4 import BeautifulSoup
import json
import os
from datetime import datetime

# --- 1. è¨­å®šå€ï¼šè«‹å°‡æ‚¨ç”³è«‹çš„keyå¡«å¯«åœ¨é€™è£¡ ---


GOOGLE_API_KEY = os.environ.get("GOOGLE_API_KEY", "AIzaSyBTyArZ1qVZNVl12pIeDRiaMx3mkY-fGcM") 
SEARCH_ENGINE_ID = os.environ.get("SEARCH_ENGINE_ID", "30e35e58d395e4cfd")  # æ‚¨çš„ Google Custom Search Engine ID

# Ollama API çš„ä½å€å’Œæ¨¡å‹åç¨±
OLLAMA_API_URL = "http://localhost:11434/api/generate"
OLLAMA_MODEL = "qwen3:0.6b" 

# --- 2. æ ¸å¿ƒåŠŸèƒ½å‡½å¼ ---
# Google_Search å‡½å¼ç”¨æ–¼ä½¿ç”¨ Google Search API é€²è¡Œæœå°‹ï¼Œä¸¦è¿”å›çµæœçš„ç¶²å€åˆ—è¡¨ã€‚ç½‘é¡µæ•°é‡é»˜è®¤ä¸º10ã€‚ 
def Google_Search(query: str, num_results: int = 10) -> list:
    """
    ä½¿ç”¨ Google Search API é€²è¡Œæœå°‹ã€‚
    :param query: æœå°‹çš„é—œéµå­—ã€‚
    :param num_results: éœ€è¦è¿”å›çš„æœå°‹çµæœæ•¸é‡ã€‚
    :return: åŒ…å«ç¶²å€çš„åˆ—è¡¨ã€‚
    """
    print(f"ğŸ” æ­£åœ¨ä½¿ç”¨ Google æœå°‹: {query}")
    url = "https://www.googleapis.com/customsearch/v1"
    params = {
        'key': GOOGLE_API_KEY,
        'cx': SEARCH_ENGINE_ID,
        'q': query,
        'num': num_results
    }
    try:
        response = requests.get(url, params=params)
        response.raise_for_status()  # å¦‚æœè«‹æ±‚å¤±æ•—å‰‡æ‹‹å‡ºç•°å¸¸
        search_results = response.json()
        urls = [item['link'] for item in search_results.get('items', [])]
        print(f"âœ… æˆåŠŸç²å–åˆ° {len(urls)} å€‹æœå°‹çµæœã€‚")
        return urls
    except Exception as e:
        print(f"âŒ Google æœå°‹å¤±æ•—: {e}")
        return []

# Scrape_website_content å‡½å¼ç”¨æ–¼çˆ¬å–æŒ‡å®šç¶²å€çš„ç¶²é æ–‡æœ¬å…§å®¹ï¼Œä¸¦è¿”å›ç´”æ–‡æœ¬ã€‚é€™è£¡ä½¿ç”¨ BeautifulSoup ä¾†è§£æ HTMLã€‚
def scrape_website_content(url: str) -> str:
    """
    çˆ¬å–æŒ‡å®šç½‘å€çš„ç½‘é¡µæ–‡æœ¬å†…å®¹ï¼Œæ·»åŠ ç¼–ç å¤„ç†ä»¥é¿å…ä¸­æ–‡ä¹±ç ã€‚
    :param url: è¦çˆ¬å–çš„ç½‘å€ã€‚
    :return: ç½‘é¡µçš„çº¯æ–‡æœ¬å†…å®¹ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›ç©ºå­—ä¸²ã€‚
    """
    print(f"ğŸ•¸ï¸ æ­£åœ¨çˆ¬å–ç¶²é : {url}")
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        # å°è¯•æ£€æµ‹ç¼–ç å¹¶æ­£ç¡®è®¾ç½®
        if response.encoding.lower() == 'iso-8859-1':
            encodings = ['utf-8', 'gbk', 'gb2312', 'gb18030']
            for enc in encodings:
                try:
                    response.encoding = enc
                    if 'ï¿½' not in response.text and 'é”›' not in response.text:
                        break
                except:
                    continue
        
        # ä½¿ç”¨ BeautifulSoup è§£æ HTML
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ç§»é™¤è„šæœ¬ã€æ ·å¼å’Œå…¶ä»–éå†…å®¹æ ‡ç­¾
        for tag in soup(['script', 'style', 'nav', 'footer', 'header', 'aside']):
            tag.decompose()
        
        # æå–å¹¶æ¸…ç†æ–‡æœ¬ï¼Œç®€åŒ–å¤„ç†
        text = soup.body.get_text(separator=' ') if soup.body else soup.get_text(separator=' ')
        text = ' '.join(text.split())  # æ›¿æ¢æ‰€æœ‰è¿ç»­ç©ºç™½å­—ç¬¦ä¸ºå•ä¸ªç©ºæ ¼
        
        content_length = len(text)
        max_length = 3000  # æé«˜åˆ°5000å­—ç¬¦ï¼Œè·å–æ›´å¤šä¸Šä¸‹æ–‡
        print(text[:max_length])  # è¾“å‡ºå‰3000å­—ç¬¦ä»¥ä¾›è°ƒè¯•
        print(f"âœ… æˆåŠŸçˆ¬å–ç½‘é¡µå†…å®¹ï¼Œé•¿åº¦: {content_length} å­—ç¬¦ï¼Œæˆªå–äº†å‰ {min(content_length, max_length)} å­—ç¬¦ã€‚")
        return text[:max_length]
    except Exception as e:
        print(f"âŒ çˆ¬å–ç¶²é å¤±æ•—: {e}")
        return ""

def ask_qwen_with_context(question: str, context: str) -> str:
    """
    å°‡å•é¡Œå’Œä¸Šä¸‹æ–‡æäº¤çµ¦æœ¬åœ°çš„ Qwen æ¨¡å‹é€²è¡Œåˆ†æå’Œå›ç­”ã€‚
    :param question: ä½¿ç”¨è€…çš„åŸå§‹å•é¡Œã€‚
    :param context: å¾ç¶²è·¯ä¸Šæª¢ç´¢åˆ°çš„åƒè€ƒè³‡æ–™ã€‚
    :return: Qwen æ¨¡å‹ç”Ÿæˆçš„å›æ‡‰ã€‚
    """
    print("ğŸ§  æ­£åœ¨å‘¼å« Qwen3 æ¨¡å‹é€²è¡Œåˆ†æå’Œå›ç­”...")
    
    today = datetime.now().strftime("%Y-%m-%d")
    # é€™æ˜¯ä¸€å€‹é—œéµçš„ Prompt Templateï¼Œå¼•å°æ¨¡å‹æ ¹æ“šä¸Šä¸‹æ–‡å›ç­”
    prompt = f"""
è«‹ä½ æ‰®æ¼”ä¸€å€‹å°ˆæ¥­çš„è³‡è¨Šåˆ†æå¸«ã€‚
ä»Šå¤©çš„æ—¥æœŸæ˜¯ï¼š{today}
æ ¹æ“šä¸‹é¢æä¾›çš„ã€Œç¶²è·¯æœå°‹åƒè€ƒè³‡æ–™ã€ï¼Œç°¡æ½”ã€æº–ç¢ºåœ°å›ç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚
è«‹ä¸è¦ä½¿ç”¨åƒè€ƒè³‡æ–™ä»¥å¤–çš„è³‡è¨Šã€‚å¦‚æœè³‡æ–™ä¸è¶³ä»¥å›ç­”ï¼Œè«‹èª å¯¦åœ°èªªã€Œæ ¹æ“šç¾æœ‰è³‡æ–™ï¼Œæˆ‘ç„¡æ³•å›ç­”é€™å€‹å•é¡Œã€ã€‚

---
[ç¶²è·¯æœå°‹åƒè€ƒè³‡æ–™]
{context}
---

[ä½¿ç”¨è€…çš„å•é¡Œ]
{question}

[ä½ çš„å›ç­”]
"""

    payload = {
        "model": OLLAMA_MODEL,
        "prompt": prompt,
        "stream": False
    }

    try:
        response = requests.post(OLLAMA_API_URL, json=payload)
        response.raise_for_status()
        response_data = response.json()
        print("âœ… Qwen3 æ¨¡å‹å›ç­”å®Œç•¢ã€‚")
        return response_data.get('response', 'æ¨¡å‹æ²’æœ‰è¿”å›æœ‰æ•ˆçš„å›ç­”ã€‚')
    except Exception as e:
        print(f"âŒ å‘¼å« Qwen3 æ¨¡å‹å¤±æ•—: {e}")
        return "ç„¡æ³•é€£æ¥åˆ°æœ¬åœ°çš„ Qwen æ¨¡å‹ã€‚"

# --- 3. ä¸»åŸ·è¡Œæµç¨‹ ---
def main():
    user_question = input("æ‚¨å¥½ï¼è«‹è¼¸å…¥æ‚¨æƒ³æŸ¥è©¢çš„å•é¡Œï¼š")
    
    # æ­¥é©Ÿä¸€ï¼šæœå°‹
    search_urls = Google_Search(user_question)
    
    if not search_urls:
        print("ç„¡æ³•ç²å–æœå°‹çµæœï¼Œç¨‹å¼çµ‚æ­¢ã€‚")
        return
        
    # æ­¥é©ŸäºŒå’Œä¸‰ï¼šæŠ“å–å’Œæ•´åˆ
    all_context = ""
    count = 0
    # é™åˆ¶æŠ“å–çš„ç¶²é æ•¸é‡ï¼Œæœ€å¤š3å€‹
    for url in search_urls:
        if count >= 3:
            break
        content = scrape_website_content(url)
        if content:
            all_context += f"[ä¾†æº: {url}]\n{content}\n\n---\n\n"
            count += 1
    if not all_context:
        print("ç„¡æ³•å¾ä»»ä½•ç¶²é ä¸ŠæŠ“å–åˆ°æœ‰æ•ˆå…§å®¹ï¼Œç¨‹å¼çµ‚æ­¢ã€‚")
        return
        
    # æ­¥é©Ÿå››ï¼šç”Ÿæˆ
    final_answer = ask_qwen_with_context(user_question, all_context)
    
    print("\n==================== æœ€çµ‚ç­”æ¡ˆ ====================\n")
    print(final_answer)
    print("\n==================================================")

if __name__ == "__main__":
    main()